#!/usr/bin/env python3

import numpy
import ne
import os
import tee
import warnings
from sklearn.naive_bayes import GaussianNB
warnings.filterwarnings('ignore')

if __name__ ==  '__main__':
    DATASET  = ne.data.nsl_kdd.dataset
    SELECTOR = ne.data.Pearsons
    THRESH   = lambda x: x > 0.5
    
    log_dir = os.path.join('results', 'feature_selection', SELECTOR.name, DATASET.name())
    os.makedirs(log_dir, exist_ok=True)
    with tee.StdoutTee(os.path.join(log_dir, 'output.log'), buff=1):
        ne.util.dump(__file__)

        results = {}
        for n_features in range(1, DATASET.num_features()):
            split = DATASET.data(selector=SELECTOR(n_features), save=False, cache=True)
            model = GaussianNB(var_smoothing=1e-15)
            model.fit(*split.train)
            stats = ne.stats.compute_statistics(THRESH, split.test.ys, model.predict(split.test.xs))
            results[n_features] = stats
            print("{} - {}".format(n_features, stats.mcc))
        print(list(map(lambda t:t[0], sorted(results.items(), key=lambda t:t[1].mcc, reverse=True))))


1 - 0.7010384300600346
2 - 0.7089198860234132
3 - 0.6564454724686409
4 - 0.7118050950235383
5 - 0.713381672627089
6 - 0.7123614479501926
7 - 0.7059339796673564
8 - 0.7058920664855566
9 - 0.7255198517222119
10 - 0.7356320975268744
11 - 0.7288975428916956
12 - 0.7326376482336935
13 - 0.7595821097108046
14 - 0.7388857352915631
15 - 0.7373072723975629
16 - 0.7402416395872047
17 - 0.7357981459054381
18 - 0.727769393278781
19 - 0.7276059419308476
20 - 0.7430547960310345
21 - 0.7409186585659379
22 - 0.7391115727320433
23 - 0.7424589602513894
24 - 0.7482299309915136
25 - 0.7565550125431912
26 - 0.7661269320298929
27 - 0.7710776921261981
28 - 0.7712208280021132
29 - 0.7693368498625082
30 - 0.7684464006030385
31 - 0.7596862790118455
32 - 0.7594862589169569
33 - 0.7588957960179016
34 - 0.7592572511955171
35 - 0.7582753196376051
36 - 0.7610661883760883
37 - 0.7613368802886445
38 - 0.7618482899959179
39 - 0.7727002297579861
40 - 0.7720185946268802
[39, 40, 28, 27, 29, 30, 26, 38, 37, 36, 31, 13, 32, 34, 33, 35, 25, 24, 20, 23, 21, 16, 22, 14, 15, 17, 10, 12, 11, 18, 19, 9, 5, 6, 4, 2, 7, 8, 1, 3]
